{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0780f853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver_manager\n",
      "  Obtaining dependency information for webdriver_manager from https://files.pythonhosted.org/packages/b1/51/b5c11cf739ac4eecde611794a0ec9df420d0239d51e73bc19eb44f02b48b/webdriver_manager-4.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\user\\anaconda3\\lib\\site-packages (from webdriver_manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from webdriver_manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2023.7.22)\n",
      "Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: webdriver_manager\n",
      "Successfully installed webdriver_manager-4.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6da530d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#conda install -c conda-forge selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e160e611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#conda install -c conda-forge chromedriver_autoinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f96ef70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromedriver-autoinstaller\n",
      "  Obtaining dependency information for chromedriver-autoinstaller from https://files.pythonhosted.org/packages/6c/ae/c9946f89b42a752b38fa33fe82676e8e8fe722f3287d9909f3bd0e11e537/chromedriver_autoinstaller-0.6.3-py3-none-any.whl.metadata\n",
      "  Downloading chromedriver_autoinstaller-0.6.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chromedriver-autoinstaller) (23.1)\n",
      "Downloading chromedriver_autoinstaller-0.6.3-py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: chromedriver-autoinstaller\n",
      "Successfully installed chromedriver-autoinstaller-0.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install chromedriver-autoinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8ec15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca5dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ebd71f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연말모임하기 좋은 역삼역 맛집\n",
      "역삼 고기집 회식 맛집 칠프로칠백식당 역삼직영점 메뉴 주차 후기\n",
      "강남/역삼맛집 가볍게 먹으려다가 D지게 먹은 (전)강남직장인의 먹리스트 후기(돼지통/일품각/한성양꼬치...\n",
      "역삼 맛집 진가와 프라이빗 초밥 강남 룸식당\n",
      "역삼동맛집 박속낙지 & 회. 역삼역, 강남 횟집\n",
      "강남역맛집 고기집 함양숯불회관 본점, 지리산 흑돼지가 맛있는 역삼역맛집\n",
      "역삼역 점심 맛집 동봉관 돼지곰탕에 잔술\n",
      "골목골목 숨겨진, 역삼역 맛집 BEST 5\n",
      "역삼역 한식 맛집 대작 돼지갈비 단체 회식장소\n",
      "서울 역삼역 닭도리탕맛집 역삼농원 역대급 숯불의 찐맛\n",
      "역삼역 룸식당 고기집 회식 모임에 최고 맛집 칠프로 칠백식당 역삼직영점 추천\n",
      "역삼역 맛집 / 역삼역 점심 갈비다움 역삼본점\n",
      "강남역 맛집 역삼역 점심 딤섬맛집 신복면관\n",
      "역삼역 맛집!!\n",
      "풍미가득한 역삼동 맛집\n",
      "역삼동 맛집 초이다이닝 추천해요!!\n",
      "서울 강남 | 쁘라텟타이 · 역삼역 태국음식 맛집 팟타이 뿌팟퐁커리 똠양꿍 세트 추천\n",
      "[서울/강남구] 아쉽게 지나간 올 한해를 평가하며, 역삼역 어복쟁반&평양냉면 <평가옥>\n",
      "역삼동맛집 마구로센 참치\n",
      "역삼맛집 회식하기 좋은 갈비맛집 라비옥\n",
      "역삼 맛집 꼭 가봐야하는 신동궁감자탕 역삼직영점 진짜 매운맛\n",
      "친구들 모임 하기 좋은 역삼동 맛집\n",
      "역삼한우, 선릉한우 - 소담한우(가성비한우, 최상급한우 맛집!)\n",
      "역삼 맛집 추천\n",
      "[강남/역삼] 줄서는 맛집 리스트, 직장인이 추천하는 내돈내산 맛집\n",
      "선릉 역삼 굴국밥 맛집 맛자랑에서 매생이굴국밥 한그릇!\n",
      "맛있어서 재방문한 역삼 맛집 스시산원청\n",
      "역삼 센터필드 맛집 더키친일뽀르노\n",
      "역삼 회식으로 가기 좋은 진갈비 맛집 라비옥 후기\n",
      "역삼 매운 갈비찜 맛집 맛있게 매콤한 갈비다움\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "# Chrome 드라이버 설치\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# 크롬 옵션 설정\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "\n",
    "# 크롬 드라이버 실행\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# 크롤링할 페이지 URL\n",
    "url = \"https://search.naver.com/search.naver?where=view&sm=tab_jum&query=%EC%97%AD%EC%82%BC+%EB%A7%9B%EC%A7%91\"\n",
    "\n",
    "# 페이지 열기\n",
    "driver.get(url)\n",
    "\n",
    "# 블로그 제목에 해당하는 부분을 선택\n",
    "titles = driver.find_elements(By.CLASS_NAME, 'title_link')\n",
    "\n",
    "# 각 블로그 제목을 출력\n",
    "for title in titles:\n",
    "    print(title.text)\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ad070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43b808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b9b8024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "링크: https://blog.naver.com/explore5468/223277407023\n",
      "링크: https://blog.naver.com/hdsign88/223300260863\n",
      "링크: https://blog.naver.com/somvly_g1/223088229214\n",
      "링크: https://blog.naver.com/1616sm/223285390935\n",
      "링크: https://blog.naver.com/dlrwnsaka/223294139086\n",
      "링크: https://blog.naver.com/arasi56/223297843724\n",
      "링크: https://blog.naver.com/aisama2/223277705523\n",
      "링크: https://post.naver.com/viewer/postView.nhn?volumeNo=27900240&memberNo=31740578&vType=VERTICAL\n",
      "링크: https://blog.naver.com/kizaki56/223282278030\n",
      "링크: https://blog.naver.com/crispynote/223298266120\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "# Chrome 드라이버 설치\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# 크롬 옵션 설정\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "\n",
    "# 크롬 드라이버 실행\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879be503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1bced3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0044c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import chromedriver_autoinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9997e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 에이전트를 설정\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "\n",
    "# 사용자 에이전트를 포함한 Chrome 옵션을 설정\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(f\"user-agent={user_agent}\")\n",
    "chrome_options.add_argument('--headless')\n",
    "\n",
    "# Chrome 드라이버를 설치\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "# Chrome 드라이버를 생성\n",
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc5bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링할 페이지 URL '역삼 맛집'\n",
    "url = \"https://search.naver.com/search.naver?where=view&sm=tab_jum&query=%EC%97%AD%EC%82%BC+%EB%A7%9B%EC%A7%91\"\n",
    "driver.get(url)\n",
    "\n",
    "blog_links = []\n",
    "\n",
    "# 블로그 제목 클래스 선택\n",
    "titles = driver.find_elements(By.CLASS_NAME, 'title_link')\n",
    "\n",
    "# 상위 10개의 블로그 링크 저장\n",
    "for title in titles[:10]:\n",
    "    blog_links.append(title.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc86a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://blog.naver.com/explore5468/223277407023\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".se_publishDate\"}\n  (Session info: chrome-headless-shell=120.0.6099.111)\nStacktrace:\n\tGetHandleVerifier [0x005E6EE3+174339]\n\t(No symbol) [0x00510A51]\n\t(No symbol) [0x00226FF6]\n\t(No symbol) [0x00259876]\n\t(No symbol) [0x00259C2C]\n\t(No symbol) [0x0028BD42]\n\t(No symbol) [0x00277054]\n\t(No symbol) [0x0028A104]\n\t(No symbol) [0x00276DA6]\n\t(No symbol) [0x00251034]\n\t(No symbol) [0x00251F8D]\n\tGetHandleVerifier [0x00684B1C+820540]\n\tsqlite3_dbdata_init [0x007453EE+653550]\n\tsqlite3_dbdata_init [0x00744E09+652041]\n\tsqlite3_dbdata_init [0x007397CC+605388]\n\tsqlite3_dbdata_init [0x00745D9B+656027]\n\t(No symbol) [0x0051FE6C]\n\t(No symbol) [0x005183B8]\n\t(No symbol) [0x005184DD]\n\t(No symbol) [0x00505818]\n\tBaseThreadInitThunk [0x750B00F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x76F47BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x76F47B8E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m\n\u001b[0;32m      8\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(page_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 제목\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#title_element = soup.find('span', {'class': 'se-title-text'})\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#title = title_element.text.strip() if title_element else \"제목 없음\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#author_id_element = soup.find('span', {'class': 'nick'})\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#author_id = author_id_element.find('a').text.strip() if author_id_element else \"작성자 ID 없음\"\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m date_element \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mse_publishDate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m author_element \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnick\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m title_element \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mse-title-text\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:831\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    828\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    829\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 831\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".se_publishDate\"}\n  (Session info: chrome-headless-shell=120.0.6099.111)\nStacktrace:\n\tGetHandleVerifier [0x005E6EE3+174339]\n\t(No symbol) [0x00510A51]\n\t(No symbol) [0x00226FF6]\n\t(No symbol) [0x00259876]\n\t(No symbol) [0x00259C2C]\n\t(No symbol) [0x0028BD42]\n\t(No symbol) [0x00277054]\n\t(No symbol) [0x0028A104]\n\t(No symbol) [0x00276DA6]\n\t(No symbol) [0x00251034]\n\t(No symbol) [0x00251F8D]\n\tGetHandleVerifier [0x00684B1C+820540]\n\tsqlite3_dbdata_init [0x007453EE+653550]\n\tsqlite3_dbdata_init [0x00744E09+652041]\n\tsqlite3_dbdata_init [0x007397CC+605388]\n\tsqlite3_dbdata_init [0x00745D9B+656027]\n\t(No symbol) [0x0051FE6C]\n\t(No symbol) [0x005183B8]\n\t(No symbol) [0x005184DD]\n\t(No symbol) [0x00505818]\n\tBaseThreadInitThunk [0x750B00F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x76F47BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x76F47B8E+238]\n"
     ]
    }
   ],
   "source": [
    "for link in blog_links:\n",
    "    print(link)\n",
    "    driver.get(link)  \n",
    "\n",
    "    # 페이지 소스\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # 제목\n",
    "    #title_element = soup.find('span', {'class': 'se-title-text'})\n",
    "    #title = title_element.text.strip() if title_element else \"제목 없음\"\n",
    "\n",
    "    # 본문\n",
    "    #content_element = soup.find('div', {'class': 'se-main-container'})\n",
    "    #content = content_element.text.strip() if content_element else \"본문 없음\"\n",
    "\n",
    "    # 작성일자\n",
    "    #publish_date_element = soup.find('span', {'class': 'se_publishDate'})\n",
    "    #publish_date = publish_date_element.text.strip() if publish_date_element else \"작성일자 없음\"\n",
    "\n",
    "    # 작성자 ID\n",
    "    #author_id_element = soup.find('span', {'class': 'nick'})\n",
    "    #author_id = author_id_element.find('a').text.strip() if author_id_element else \"작성자 ID 없음\"\n",
    "    date_element = driver.find_element(By.CLASS_NAME, 'se_publishDate')\n",
    "    author_element = driver.find_element(By.CLASS_NAME, 'nick')\n",
    "    title_element = driver.find_element(By.CLASS_NAME, 'se-title-text')\n",
    "\n",
    "    \n",
    "    print(\"작성일자:\", date_element.text)\n",
    "    print(\"작성자 ID:\", author_element.text)\n",
    "    print(\"제목:\", title_element.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c26488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://blog.naver.com/explore5468/223277407023\n",
      "제목: 제목 없음\n",
      "본문: 본문 없음\n",
      "작성일자: 작성일자 없음\n",
      "작성자 ID: 작성자 ID 없음\n",
      "----\n",
      "https://blog.naver.com/hdsign88/223300260863\n",
      "제목: 제목 없음\n",
      "본문: 본문 없음\n",
      "작성일자: 작성일자 없음\n",
      "작성자 ID: 작성자 ID 없음\n",
      "----\n",
      "https://blog.naver.com/somvly_g1/223088229214\n",
      "제목: 제목 없음\n",
      "본문: 본문 없음\n",
      "작성일자: 작성일자 없음\n",
      "작성자 ID: 작성자 ID 없음\n",
      "----\n",
      "https://blog.naver.com/1616sm/223285390935\n",
      "제목: 제목 없음\n",
      "본문: 본문 없음\n",
      "작성일자: 작성일자 없음\n",
      "작성자 ID: 작성자 ID 없음\n",
      "----\n",
      "https://blog.naver.com/dlrwnsaka/223294139086\n",
      "제목: 제목 없음\n",
      "본문: 본문 없음\n",
      "작성일자: 작성일자 없음\n",
      "작성자 ID: 작성자 ID 없음\n",
      "----\n",
      "https://blog.naver.com/dorami7/223302949319\n",
      "제목: 제목 없음\n",
      "본문: 본문 없음\n",
      "작성일자: 작성일자 없음\n",
      "작성자 ID: 작성자 ID 없음\n",
      "----\n",
      "https://blog.naver.com/arasi56/223297843724\n",
      "제목: 제목 없음\n",
      "본문: 본문 없음\n",
      "작성일자: 작성일자 없음\n",
      "작성자 ID: 작성자 ID 없음\n",
      "----\n",
      "https://post.naver.com/viewer/postView.nhn?volumeNo=27900240&memberNo=31740578&vType=VERTICAL\n",
      "제목: 제목 없음\n",
      "본문: 본문 없음\n",
      "작성일자: 2020.04.06. 12:00\n",
      "작성자 ID: 작성자 ID 없음\n",
      "----\n",
      "https://blog.naver.com/aisama2/223277705523\n",
      "제목: 제목 없음\n",
      "본문: 본문 없음\n",
      "작성일자: 작성일자 없음\n",
      "작성자 ID: 작성자 ID 없음\n",
      "----\n",
      "https://blog.naver.com/crispynote/223298266120\n",
      "제목: 제목 없음\n",
      "본문: 본문 없음\n",
      "작성일자: 작성일자 없음\n",
      "작성자 ID: 작성자 ID 없음\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# 드라이버 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da8559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de921c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87da7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "070af342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_5728\\1721665376.py:22: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(driver_path, options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색할 키워드를 입력해주세요:역삼맛집\n",
      "\n",
      "크롤링을 끝낼 위치를 입력해주세요. (기본값:1, 최대값:100):1\n",
      "\n",
      " 1 ~  1 페이지 까지 크롤링을 진행 합니다\n",
      "\n",
      "한번에 가져올 페이지 개수를 입력해주세요.(기본값:10, 최대값: 100):10\n",
      "\n",
      "한번에 가져올 페이지 :  10 페이지\n",
      "https://blog.naver.com/mmm7962/223240326044\n",
      "https://blog.naver.com/1616sm/223285390935\n",
      "https://blog.naver.com/dorami7/223302949319\n",
      "https://blog.naver.com/dlrwnsaka/223294139086\n",
      "https://blog.naver.com/aisama2/223277705523\n",
      "https://blog.naver.com/kirirrring/223302437706\n",
      "https://blog.naver.com/kshjbe/223268326565\n",
      "https://blog.naver.com/valueyey/223245002859\n",
      "https://blog.naver.com/jjacmn/223285550735\n",
      "https://blog.naver.com/allya_hj/223217190342\n",
      "https://blog.naver.com/tkfkdgo213/223244021544\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 122\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# DataFrame을 엑셀 파일로 저장합니다\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     news_df\u001b[38;5;241m.\u001b[39mto_excel(excel_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: NDFrame.to_excel() got an unexpected keyword argument 'encoding'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 125\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     contents\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m에러\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 125\u001b[0m     news_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m제목\u001b[39m\u001b[38;5;124m'\u001b[39m: titles, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m내용\u001b[39m\u001b[38;5;124m'\u001b[39m: contents, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m날짜\u001b[39m\u001b[38;5;124m'\u001b[39m: postdate})\n\u001b[0;32m    126\u001b[0m     news_df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblog.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    653\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    660\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "\n",
    "# 웹드라이버 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "# 버전에 상관 없이 os에 설치된 크롬 브라우저 사용\n",
    "driver_path = ChromeDriverManager().install()\n",
    "driver = webdriver.Chrome(driver_path, options=options)\n",
    "driver.implicitly_wait(3)\n",
    "# 버전에 상관 없이 os에 설치된 크롬 브라우저 사용\n",
    "\n",
    "\n",
    "# Naver API key 입력\n",
    "client_id = 'vIYTplPNAfOnVh9hEiRl' \n",
    "client_secret = 'P58nRJiI68'\n",
    "\n",
    "\n",
    "# selenium으로 검색 페이지 불러오기 #\n",
    "naver_urls = []\n",
    "postdate = []\n",
    "titles = []\n",
    "\n",
    "# 검색어 입력\n",
    "keword = input(\"검색할 키워드를 입력해주세요:\")\n",
    "encText = urllib.parse.quote(keword)\n",
    "\n",
    "# 검색을 끝낼 페이지 입력\n",
    "end = input(\"\\n크롤링을 끝낼 위치를 입력해주세요. (기본값:1, 최대값:100):\")  \n",
    "if end == \"\":\n",
    "    end = 1\n",
    "else:\n",
    "    end = int(end)\n",
    "print(\"\\n 1 ~ \", end, \"페이지 까지 크롤링을 진행 합니다\")\n",
    "\n",
    "# 한번에 가져올 페이지 입력\n",
    "display = input(\"\\n한번에 가져올 페이지 개수를 입력해주세요.(기본값:10, 최대값: 100):\")\n",
    "if display == \"\":\n",
    "    display = 10\n",
    "else:\n",
    "    display = int(display)\n",
    "print(\"\\n한번에 가져올 페이지 : \", display, \"페이지\")\n",
    "\n",
    "\n",
    "for start in range(end):\n",
    "    url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText + \"&start=\" + str(start+1) + \"&display=\" + str(display+1) # JSON 결과\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        \n",
    "        data = json.loads(response_body.decode('utf-8'))['items']\n",
    "        for row in data:\n",
    "            if('blog.naver' in row['link']):\n",
    "                naver_urls.append(row['link'])\n",
    "                postdate.append(row['postdate'])\n",
    "                title = row['title']\n",
    "                # html태그제거\n",
    "                pattern1 = '<[^>]*>'\n",
    "                title = re.sub(pattern=pattern1, repl='', string=title)\n",
    "                titles.append(title)\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n",
    "\n",
    "\n",
    "###naver 기사 본문 및 제목 가져오기###\n",
    "\n",
    "# ConnectionError방지\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/98.0.4758.102\"}\n",
    "\n",
    "\n",
    "contents = []\n",
    "comments_texts = []\n",
    "try:\n",
    "    for i in naver_urls:\n",
    "        print(i)\n",
    "        driver.get(i)\n",
    "        time.sleep(5)  # 필요에 따라 대기 시간을 조정하세요\n",
    "\n",
    "        iframe = driver.find_element(By.ID, \"mainFrame\")\n",
    "        driver.switch_to.frame(iframe)\n",
    "\n",
    "        source = driver.page_source\n",
    "        html = BeautifulSoup(source, \"html.parser\")\n",
    "\n",
    "        # 텍스트 내용 추출\n",
    "        content = html.select(\"div.se-main-container\")\n",
    "        content = ''.join(str(content))\n",
    "\n",
    "        # HTML 태그 제거 및 텍스트 정리\n",
    "        content = re.sub(pattern=pattern1, repl='', string=content)\n",
    "        pattern2 = \"\"\"[\\n\\n\\n\\n\\n// flash 오류를 우회하기 위한 함수 추가\\nfunction _flash_removeCallback() {}\"\"\"\n",
    "        content = content.replace(pattern2, '')\n",
    "        content = content.replace('\\n', '')\n",
    "        content = content.replace('\\u200b', '')\n",
    "        contents.append(content)\n",
    "\n",
    "    news_df = pd.DataFrame({'제목': titles, '내용': contents, '날짜': postdate})\n",
    "\n",
    "    # 엑셀 파일을 저장할 위치를 바탕화면으로 지정합니다\n",
    "    desktop_path = os.path.join(os.path.join(os.environ['USERPROFILE']), 'Desktop')\n",
    "    excel_file_path = os.path.join(desktop_path, 'blog.xlsx')\n",
    "\n",
    "    # DataFrame을 엑셀 파일로 저장합니다\n",
    "    news_df.to_excel(excel_file_path, index=False, encoding='utf-8-sig')\n",
    "except:\n",
    "    contents.append('에러')\n",
    "    news_df = pd.DataFrame({'제목': titles, '내용': contents, '날짜': postdate})\n",
    "    news_df.to_excel('blog.xlsx', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f8d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
